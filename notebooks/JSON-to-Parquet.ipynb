{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import os\n",
    "import psutil\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import threading\n",
    "import time\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from typing import Iterator, List, Tuple\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/corpus/msmarco-docs.json.gz\"\n",
    "output_dir = \"../data/corpus/parquet_chunks/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def monitor_memory(interval: int = 5):\n",
    "    \"\"\"Context manager for memory monitoring.\"\"\"\n",
    "    stop_thread = threading.Event()\n",
    "    \n",
    "    def _monitor():\n",
    "        while not stop_thread.is_set():\n",
    "            mem = psutil.virtual_memory()\n",
    "            swap = psutil.swap_memory()\n",
    "            logger.info(\n",
    "                f\"RAM: {mem.used/1e9:.1f}/{mem.total/1e9:.1f}GB \"\n",
    "                f\"Swap: {swap.used/1e9:.1f}/{swap.total/1e9:.1f}GB\"\n",
    "            )\n",
    "            time.sleep(interval)\n",
    "    \n",
    "    thread = threading.Thread(target=_monitor, daemon=True)\n",
    "    try:\n",
    "        thread.start()\n",
    "        yield\n",
    "    finally:\n",
    "        stop_thread.set()\n",
    "        thread.join(timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_optimal_chunk_size(\n",
    "    sample_size: int = 1000,\n",
    "    target_chunk_memory: float = 0.2,  # GB\n",
    "    input_file: str = None\n",
    ") -> int:\n",
    "    \"\"\"Estimate optimal chunk size based on sample data.\"\"\"\n",
    "    if not input_file:\n",
    "        return 10000  # Default fallback\n",
    "        \n",
    "    total_memory = psutil.virtual_memory().total / 1e9  # GB\n",
    "    target_memory = total_memory * target_chunk_memory\n",
    "    \n",
    "    # Sample some lines to estimate average row size\n",
    "    with gzip.open(input_file, 'rt') as f:\n",
    "        sample = [next(f) for _ in range(sample_size)]\n",
    "    \n",
    "    avg_row_size = sum(len(line.encode()) for line in sample) / len(sample)\n",
    "    chunk_size = int((target_memory * 1e9) / avg_row_size)\n",
    "    \n",
    "    return max(1000, min(chunk_size, 30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_compressed_json(\n",
    "    file_path: str,\n",
    "    chunk_size: int\n",
    ") -> Iterator[List[str]]:\n",
    "    \"\"\"Generator to efficiently read compressed JSON file in chunks.\"\"\"\n",
    "    batch = []\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        for line in f:\n",
    "            batch.append(line.strip())\n",
    "            if len(batch) >= chunk_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "def process_chunk(chunk_data: Tuple[List[str], int, str]) -> None:\n",
    "    \"\"\"Process a single chunk of data.\n",
    "    \n",
    "    Args:\n",
    "        chunk_data: Tuple containing (data_batch, chunk_index, output_directory)\n",
    "    \"\"\"\n",
    "    batch, chunk_idx, output_dir = chunk_data\n",
    "    try:\n",
    "        # Convert directly to Arrow Table for better memory efficiency\n",
    "        df = pl.read_ndjson(StringIO(\"\\n\".join(batch)))\n",
    "        table = df.to_arrow()\n",
    "        \n",
    "        chunk_file = os.path.join(output_dir, f\"chunk_{chunk_idx:05d}.parquet\")\n",
    "        pq.write_table(\n",
    "            table,\n",
    "            chunk_file,\n",
    "            compression='snappy',\n",
    "            row_group_size=30000\n",
    "        )\n",
    "        logger.info(f\"Saved chunk {chunk_idx} to {chunk_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing chunk {chunk_idx}: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_parquet(\n",
    "    input_file: str,\n",
    "    output_dir: str,\n",
    "    chunk_size: int = estimate_optimal_chunk_size(input_file=input_file),\n",
    "    n_workers: int = max(1, cpu_count() - 1)\n",
    ") -> None:\n",
    "    \"\"\"Main conversion function with improved error handling and resource management.\"\"\"\n",
    "    \n",
    "    logger.info(f\"Starting conversion with chunk_size={chunk_size}, workers={n_workers}\")\n",
    "    \n",
    "    with monitor_memory():\n",
    "        try:\n",
    "            chunks = read_compressed_json(input_file, chunk_size)\n",
    "            with Pool(n_workers) as pool:\n",
    "                # Process chunks with progress tracking\n",
    "                for i, _ in enumerate(\n",
    "                    pool.imap_unordered(\n",
    "                        process_chunk,\n",
    "                        ((chunk, idx, output_dir) for idx, chunk in enumerate(chunks))\n",
    "                    )\n",
    "                ):\n",
    "                    if (i + 1) % 10 == 0:\n",
    "                        logger.info(f\"Processed {i + 1} chunks\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Conversion failed: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            logger.info(\"Conversion completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting conversion with chunk_size=30000, workers=7\n",
      "INFO:__main__:RAM: 1.8/7.2GB Swap: 1.0/36.5GB\n",
      "INFO:__main__:RAM: 3.6/7.2GB Swap: 1.0/36.5GB\n",
      "INFO:__main__:Saved chunk 0 to ../data/corpus/parquet_chunks/chunk_00000.parquet\n",
      "INFO:__main__:Saved chunk 1 to ../data/corpus/parquet_chunks/chunk_00001.parquet\n",
      "INFO:__main__:RAM: 4.4/7.2GB Swap: 1.0/36.5GB\n",
      "INFO:__main__:Saved chunk 2 to ../data/corpus/parquet_chunks/chunk_00002.parquet\n",
      "INFO:__main__:Saved chunk 3 to ../data/corpus/parquet_chunks/chunk_00003.parquet\n",
      "INFO:__main__:RAM: 4.4/7.2GB Swap: 1.0/36.5GB\n",
      "INFO:__main__:Saved chunk 4 to ../data/corpus/parquet_chunks/chunk_00004.parquet\n",
      "INFO:__main__:RAM: 5.1/7.2GB Swap: 1.3/36.5GB\n",
      "INFO:__main__:Saved chunk 5 to ../data/corpus/parquet_chunks/chunk_00005.parquet\n",
      "INFO:__main__:Saved chunk 6 to ../data/corpus/parquet_chunks/chunk_00006.parquet\n",
      "INFO:__main__:RAM: 6.1/7.2GB Swap: 1.5/36.5GB\n",
      "INFO:__main__:Saved chunk 7 to ../data/corpus/parquet_chunks/chunk_00007.parquet\n",
      "INFO:__main__:Saved chunk 8 to ../data/corpus/parquet_chunks/chunk_00008.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.6/36.5GB\n",
      "INFO:__main__:Saved chunk 9 to ../data/corpus/parquet_chunks/chunk_00009.parquet\n",
      "INFO:__main__:Processed 10 chunks\n",
      "INFO:__main__:Saved chunk 10 to ../data/corpus/parquet_chunks/chunk_00010.parquet\n",
      "INFO:__main__:RAM: 5.2/7.2GB Swap: 1.6/36.5GB\n",
      "INFO:__main__:Saved chunk 11 to ../data/corpus/parquet_chunks/chunk_00011.parquet\n",
      "INFO:__main__:RAM: 5.0/7.2GB Swap: 1.7/36.5GB\n",
      "INFO:__main__:Saved chunk 12 to ../data/corpus/parquet_chunks/chunk_00012.parquet\n",
      "INFO:__main__:Saved chunk 13 to ../data/corpus/parquet_chunks/chunk_00013.parquet\n",
      "INFO:__main__:RAM: 5.0/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:RAM: 6.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 14 to ../data/corpus/parquet_chunks/chunk_00014.parquet\n",
      "INFO:__main__:Saved chunk 15 to ../data/corpus/parquet_chunks/chunk_00015.parquet\n",
      "INFO:__main__:Saved chunk 16 to ../data/corpus/parquet_chunks/chunk_00016.parquet\n",
      "INFO:__main__:RAM: 5.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 17 to ../data/corpus/parquet_chunks/chunk_00017.parquet\n",
      "INFO:__main__:RAM: 5.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 18 to ../data/corpus/parquet_chunks/chunk_00018.parquet\n",
      "INFO:__main__:Saved chunk 19 to ../data/corpus/parquet_chunks/chunk_00019.parquet\n",
      "INFO:__main__:Processed 20 chunks\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 20 to ../data/corpus/parquet_chunks/chunk_00020.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 21 to ../data/corpus/parquet_chunks/chunk_00021.parquet\n",
      "INFO:__main__:Saved chunk 22 to ../data/corpus/parquet_chunks/chunk_00022.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 23 to ../data/corpus/parquet_chunks/chunk_00023.parquet\n",
      "INFO:__main__:RAM: 6.1/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 24 to ../data/corpus/parquet_chunks/chunk_00024.parquet\n",
      "INFO:__main__:Saved chunk 25 to ../data/corpus/parquet_chunks/chunk_00025.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 26 to ../data/corpus/parquet_chunks/chunk_00026.parquet\n",
      "INFO:__main__:Saved chunk 27 to ../data/corpus/parquet_chunks/chunk_00027.parquet\n",
      "INFO:__main__:RAM: 5.1/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 28 to ../data/corpus/parquet_chunks/chunk_00028.parquet\n",
      "INFO:__main__:RAM: 6.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 29 to ../data/corpus/parquet_chunks/chunk_00029.parquet\n",
      "INFO:__main__:Processed 30 chunks\n",
      "INFO:__main__:Saved chunk 30 to ../data/corpus/parquet_chunks/chunk_00030.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 31 to ../data/corpus/parquet_chunks/chunk_00031.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 32 to ../data/corpus/parquet_chunks/chunk_00032.parquet\n",
      "INFO:__main__:Saved chunk 33 to ../data/corpus/parquet_chunks/chunk_00033.parquet\n",
      "INFO:__main__:RAM: 6.4/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 34 to ../data/corpus/parquet_chunks/chunk_00034.parquet\n",
      "INFO:__main__:Saved chunk 35 to ../data/corpus/parquet_chunks/chunk_00035.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 36 to ../data/corpus/parquet_chunks/chunk_00036.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 37 to ../data/corpus/parquet_chunks/chunk_00037.parquet\n",
      "INFO:__main__:Saved chunk 38 to ../data/corpus/parquet_chunks/chunk_00038.parquet\n",
      "INFO:__main__:RAM: 6.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 39 to ../data/corpus/parquet_chunks/chunk_00039.parquet\n",
      "INFO:__main__:Processed 40 chunks\n",
      "INFO:__main__:Saved chunk 40 to ../data/corpus/parquet_chunks/chunk_00040.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 41 to ../data/corpus/parquet_chunks/chunk_00041.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 42 to ../data/corpus/parquet_chunks/chunk_00042.parquet\n",
      "INFO:__main__:Saved chunk 43 to ../data/corpus/parquet_chunks/chunk_00043.parquet\n",
      "INFO:__main__:RAM: 6.1/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 44 to ../data/corpus/parquet_chunks/chunk_00044.parquet\n",
      "INFO:__main__:Saved chunk 45 to ../data/corpus/parquet_chunks/chunk_00045.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 46 to ../data/corpus/parquet_chunks/chunk_00046.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 47 to ../data/corpus/parquet_chunks/chunk_00047.parquet\n",
      "INFO:__main__:Saved chunk 48 to ../data/corpus/parquet_chunks/chunk_00048.parquet\n",
      "INFO:__main__:RAM: 6.0/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 49 to ../data/corpus/parquet_chunks/chunk_00049.parquet\n",
      "INFO:__main__:Processed 50 chunks\n",
      "INFO:__main__:Saved chunk 50 to ../data/corpus/parquet_chunks/chunk_00050.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 51 to ../data/corpus/parquet_chunks/chunk_00051.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 52 to ../data/corpus/parquet_chunks/chunk_00052.parquet\n",
      "INFO:__main__:Saved chunk 53 to ../data/corpus/parquet_chunks/chunk_00053.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 54 to ../data/corpus/parquet_chunks/chunk_00054.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 55 to ../data/corpus/parquet_chunks/chunk_00055.parquet\n",
      "INFO:__main__:Saved chunk 56 to ../data/corpus/parquet_chunks/chunk_00056.parquet\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 57 to ../data/corpus/parquet_chunks/chunk_00057.parquet\n",
      "INFO:__main__:Saved chunk 58 to ../data/corpus/parquet_chunks/chunk_00058.parquet\n",
      "INFO:__main__:RAM: 5.1/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 59 to ../data/corpus/parquet_chunks/chunk_00059.parquet\n",
      "INFO:__main__:Processed 60 chunks\n",
      "INFO:__main__:RAM: 5.6/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 60 to ../data/corpus/parquet_chunks/chunk_00060.parquet\n",
      "INFO:__main__:Saved chunk 61 to ../data/corpus/parquet_chunks/chunk_00061.parquet\n",
      "INFO:__main__:RAM: 5.7/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 62 to ../data/corpus/parquet_chunks/chunk_00062.parquet\n",
      "INFO:__main__:Saved chunk 63 to ../data/corpus/parquet_chunks/chunk_00063.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 64 to ../data/corpus/parquet_chunks/chunk_00064.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 65 to ../data/corpus/parquet_chunks/chunk_00065.parquet\n",
      "INFO:__main__:Saved chunk 66 to ../data/corpus/parquet_chunks/chunk_00066.parquet\n",
      "INFO:__main__:RAM: 5.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 67 to ../data/corpus/parquet_chunks/chunk_00067.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 68 to ../data/corpus/parquet_chunks/chunk_00068.parquet\n",
      "INFO:__main__:Saved chunk 69 to ../data/corpus/parquet_chunks/chunk_00069.parquet\n",
      "INFO:__main__:Processed 70 chunks\n",
      "INFO:__main__:RAM: 5.9/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 70 to ../data/corpus/parquet_chunks/chunk_00070.parquet\n",
      "INFO:__main__:Saved chunk 71 to ../data/corpus/parquet_chunks/chunk_00071.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 72 to ../data/corpus/parquet_chunks/chunk_00072.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 73 to ../data/corpus/parquet_chunks/chunk_00073.parquet\n",
      "INFO:__main__:Saved chunk 74 to ../data/corpus/parquet_chunks/chunk_00074.parquet\n",
      "INFO:__main__:RAM: 6.2/7.2GB Swap: 1.8/36.5GB\n",
      "INFO:__main__:Saved chunk 75 to ../data/corpus/parquet_chunks/chunk_00075.parquet\n",
      "INFO:__main__:Saved chunk 76 to ../data/corpus/parquet_chunks/chunk_00076.parquet\n",
      "INFO:__main__:RAM: 5.1/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 77 to ../data/corpus/parquet_chunks/chunk_00077.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 78 to ../data/corpus/parquet_chunks/chunk_00078.parquet\n",
      "INFO:__main__:Saved chunk 79 to ../data/corpus/parquet_chunks/chunk_00079.parquet\n",
      "INFO:__main__:Processed 80 chunks\n",
      "INFO:__main__:RAM: 5.9/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 80 to ../data/corpus/parquet_chunks/chunk_00080.parquet\n",
      "INFO:__main__:Saved chunk 81 to ../data/corpus/parquet_chunks/chunk_00081.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 82 to ../data/corpus/parquet_chunks/chunk_00082.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 83 to ../data/corpus/parquet_chunks/chunk_00083.parquet\n",
      "INFO:__main__:Saved chunk 84 to ../data/corpus/parquet_chunks/chunk_00084.parquet\n",
      "INFO:__main__:RAM: 6.0/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 85 to ../data/corpus/parquet_chunks/chunk_00085.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 86 to ../data/corpus/parquet_chunks/chunk_00086.parquet\n",
      "INFO:__main__:Saved chunk 87 to ../data/corpus/parquet_chunks/chunk_00087.parquet\n",
      "INFO:__main__:RAM: 6.2/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 88 to ../data/corpus/parquet_chunks/chunk_00088.parquet\n",
      "INFO:__main__:Saved chunk 89 to ../data/corpus/parquet_chunks/chunk_00089.parquet\n",
      "INFO:__main__:Processed 90 chunks\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 90 to ../data/corpus/parquet_chunks/chunk_00090.parquet\n",
      "INFO:__main__:RAM: 5.5/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 91 to ../data/corpus/parquet_chunks/chunk_00091.parquet\n",
      "INFO:__main__:Saved chunk 92 to ../data/corpus/parquet_chunks/chunk_00092.parquet\n",
      "INFO:__main__:RAM: 6.1/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 93 to ../data/corpus/parquet_chunks/chunk_00093.parquet\n",
      "INFO:__main__:Saved chunk 94 to ../data/corpus/parquet_chunks/chunk_00094.parquet\n",
      "INFO:__main__:RAM: 5.3/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 95 to ../data/corpus/parquet_chunks/chunk_00095.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 96 to ../data/corpus/parquet_chunks/chunk_00096.parquet\n",
      "INFO:__main__:Saved chunk 97 to ../data/corpus/parquet_chunks/chunk_00097.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 98 to ../data/corpus/parquet_chunks/chunk_00098.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 99 to ../data/corpus/parquet_chunks/chunk_00099.parquet\n",
      "INFO:__main__:Processed 100 chunks\n",
      "INFO:__main__:Saved chunk 100 to ../data/corpus/parquet_chunks/chunk_00100.parquet\n",
      "INFO:__main__:RAM: 6.3/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 101 to ../data/corpus/parquet_chunks/chunk_00101.parquet\n",
      "INFO:__main__:Saved chunk 102 to ../data/corpus/parquet_chunks/chunk_00102.parquet\n",
      "INFO:__main__:RAM: 5.2/7.2GB Swap: 1.9/36.5GB\n",
      "INFO:__main__:Saved chunk 103 to ../data/corpus/parquet_chunks/chunk_00103.parquet\n",
      "INFO:__main__:RAM: 5.4/7.2GB Swap: 2.0/36.5GB\n",
      "INFO:__main__:Saved chunk 104 to ../data/corpus/parquet_chunks/chunk_00104.parquet\n",
      "INFO:__main__:Saved chunk 105 to ../data/corpus/parquet_chunks/chunk_00105.parquet\n",
      "INFO:__main__:Saved chunk 107 to ../data/corpus/parquet_chunks/chunk_00107.parquet\n",
      "INFO:__main__:RAM: 6.2/7.2GB Swap: 2.0/36.5GB\n",
      "INFO:__main__:Saved chunk 106 to ../data/corpus/parquet_chunks/chunk_00106.parquet\n",
      "INFO:__main__:Conversion completed\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_parquet(input_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "def merge_parquet_files_streaming(output_dir: str, final_path: str) -> None:\n",
    "    \"\"\"Merge Parquet chunks into a single file incrementally.\"\"\"\n",
    "    chunk_files = glob.glob(os.path.join(output_dir, \"*.parquet\"))\n",
    "    logger.info(f\"Found {len(chunk_files)} chunks to merge\")\n",
    "\n",
    "    with tqdm(total=len(chunk_files), desc=\"Merging chunks\") as pbar:\n",
    "        writer = None\n",
    "        for file in chunk_files:\n",
    "            table = pq.read_table(file)  # Read as Arrow Table\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(final_path, table.schema, compression=\"snappy\")\n",
    "            writer.write_table(table)  # Append to the output file\n",
    "            pbar.update(1)\n",
    "        \n",
    "        if writer:\n",
    "            writer.close()  # Finalize the Parquet file\n",
    "    \n",
    "    logger.info(f\"Merged all chunks into: {final_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Found 108 chunks to merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging chunks: 100%|██████████| 108/108 [02:40<00:00,  1.49s/it]\n",
      "INFO:__main__:Merged all chunks into: ../data/corpus/cleaned_msmarco-docs.parquet\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../data/corpus/cleaned_chunks/\"\n",
    "merge_parquet_files_streaming(output_dir, \"../data/corpus/cleaned_msmarco-docs.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
